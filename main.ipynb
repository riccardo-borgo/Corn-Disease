{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corn Disease Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to buil models (specifically neural networks) that are able to classify images of corn leaves based on a specific disease.\n",
    "\n",
    "The different diseases are:\n",
    "- **Blight**: foliar disease of corn (maize) caused by a parasite. With its characteristic cigar-shaped lesions, this disease can cause significant yield loss in susceptible corn hybrids\n",
    "- **Common Rust**: caused by the a fungus and occurs every growing season. It is seldom a concern in hybrid corn. Early symptoms of common rust are chlorotic flecks on the leaf surface\n",
    "- **Gray Leaf Spot**: it is a foliar fungal disease that affects maize. GLS is considered one of the most significant yield-limiting diseases of corn worldwide. There are two fungal pathogens that cause GLS. Symptoms seen on corn include leaf lesions, discoloration (chlorosis), and foliar blight\n",
    "\n",
    "After briefly discussing some tecnical aspects about biology let's jump into something more interesting for us.\n",
    "\n",
    "We started with a folder, divided into subfolders, containing the different leaf images divided according to the disease. The first step was to build an actual dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "from PIL.ImageOps import crop, flip, mirror\n",
    "import os\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42 # setting a constant random state for every methos that uses randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    name = ['Blight', 'Common_Rust', 'Gray_Leaf_Spot', 'Healthy']\n",
    "    final_images = []\n",
    "    final_labels = []\n",
    "\n",
    "    for disease in name:\n",
    "        folder_path = 'Corn Images/' + disease\n",
    "        images = []\n",
    "        labels = [disease] * len(os.listdir(folder_path))\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = Image.open(img_path)\n",
    "            images.append(img)\n",
    "\n",
    "        final_images.extend(images)\n",
    "        final_labels.extend(labels)\n",
    "\n",
    "    return final_images, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = create_data()\n",
    "dataset = pd.DataFrame({'Image': result[0], 'Label': result[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a check to see if all the images have been loaded\n",
    "print(dataset[dataset['Label'] == 'Blight'].count())\n",
    "print(dataset[dataset['Label'] == 'Common_Rust'].count())\n",
    "print(dataset[dataset['Label'] == 'Gray_Leaf_Spot'].count())\n",
    "print(dataset[dataset['Label'] == 'Healthy'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    image = image.copy()\n",
    "    plt.imshow(image, aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "n_cols = 3\n",
    "n_rows = 2\n",
    "indexes = rng.choice(len(dataset), n_cols * n_rows)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "for ii, id in enumerate(indexes, 1):\n",
    "    plt.subplot(n_rows, n_cols, ii)\n",
    "    image = dataset['Image'][int(id)]\n",
    "    show_image(image)\n",
    "    plt.title(dataset['Label'][int(id)])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette('hls', 4)\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.histplot(dataset['Label'], bins=4, shrink=0.6, kde=False, color=palette[2])\n",
    "\n",
    "plt.xlabel('Cateogry')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of the Labels')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[['Image', 'Label']] # using another variable to leave the original dataset intact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x['Image'], x['Label'], test_size=0.2, random_state=RANDOM_STATE, shuffle=True, stratify=x['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the stratification\n",
    "print(y_train.count())\n",
    "print(y_test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "\n",
    "Y_train = enc.fit_transform(y_train[:, np.newaxis]).toarray()\n",
    "Y_test = enc.transform(y_test[:, np.newaxis]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resize(content):\n",
    "    return content.resize((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomRotation(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        return content.rotate(np.random.randint(-45, 45))\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomHorizontalFlip(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        return mirror(content)\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomVerticalFlip(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        return flip(content)\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomZoom(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        cropped = crop(content, np.random.randint(0, 50))\n",
    "        return cropped.resize((224, 224))\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustContrast(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        return ImageEnhance.Contrast(content).enhance(np.random.uniform(0.5, 1.5))\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdjustBrightness(content):\n",
    "    p = 0.2\n",
    "    if np.random.random() < p:\n",
    "        return ImageEnhance.Brightness(content).enhance(np.random.uniform(0.5, 1.5))\n",
    "    else:\n",
    "        return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAugmentation(content):\n",
    "    content = RandomRotation(content)\n",
    "    content = RandomHorizontalFlip(content)\n",
    "    content = RandomVerticalFlip(content)\n",
    "    content = RandomZoom(content)\n",
    "    content = AdjustContrast(content)\n",
    "    content = AdjustBrightness(content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(Resize)\n",
    "X_test = X_test.apply(Resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(DataAugmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IF IT WORKS\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "n_cols = 3\n",
    "n_rows = 2\n",
    "indexes = rng.choice(len(X_train), n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 9))\n",
    "\n",
    "for ii, id in enumerate(indexes, 1):\n",
    "    axes[0] = x['Image'][int(id)]\n",
    "    show_image(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "for ii, id in enumerate(indexes, 1):\n",
    "    axes[1] = X_train[int(id)]\n",
    "    show_image(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToNumpy(content):\n",
    "    return np.asarray(content, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(ToNumpy)\n",
    "X_test = X_test.apply(ToNumpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rescaling(content):\n",
    "    return content / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(Rescaling)\n",
    "X_test = X_test.apply(Rescaling) # check if it is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_test = Y_test.values\n",
    "Y_train = Y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Input(shape=input_shape))\n",
    "\n",
    "classifier.add(Conv2D(16, (3, 3), input_shape=input_shape, activation='relu', kernel_initializer='random_normal', strides=(1, 1), name = 'Conv2D_16'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), name = 'MaxPooling2D_(2,2)'))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=input_shape, activation='relu', kernel_initializer='random_normal', strides=(1, 1), name = 'Conv2D_32'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), name = 'MaxPooling2D_(2,2)_1'))\n",
    "\n",
    "classifier.add(Conv2D(64, (3, 3), input_shape=input_shape, activation='relu', kernel_initializer='random_normal', strides=(1, 1), name = 'Conv2D_64'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), name = 'MaxPooling2D_(2,2)_2'))\n",
    "\n",
    "classifier.add(Conv2D(128, (3, 3), input_shape=input_shape, activation='relu', kernel_initializer='random_normal', strides=(1, 1), name = 'Conv2D_128'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2), name = 'MaxPooling2D_(2,2)_3'))\n",
    "\n",
    "classifier.add(Dropout(0.5), name = 'Dropout')\n",
    "\n",
    "classifier.add(Flatten(name = 'Flatten'))\n",
    "\n",
    "classifier.add(Dense(units=4, activation='softmax', kernel_initializer='random_normal', name = 'Dense_SoftMax'))\n",
    "\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(classifier, to_file='CNN_ours.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = classifier.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
